from snakemake.utils import Paramspace
import yaml

#def load_config(path):
#    with open(path, 'r') as stream:
#        config = yaml.safe_load(stream)
#    return config

import pandas as pd

configfile: "config/config.yaml"

module vpipe_uganda:
    snakefile: github("cbg-ethz/V-pipe", path="workflow/Snakefile", tag="v3.0.0.pre1")
    config: config["vpipe_uganda"]
    replace_prefix: {"results/": "results_uganda/"}

use rule * from vpipe_uganda as vpipe_uganda_*

rule all:
    input:
        rules.vpipe_uganda_all.input,
        "results_uganda/csv_files/coverage.uganda.csv",
        "results_uganda/csv_files/mutations.uganda.csv",
    default_target: True

rule coverage_csv:
    input:
        fnames_coverage=expand("{dataset}/alignments/coverage.tsv.gz", dataset= vpipe_uganda.datasets),
    output:
        fname_coverage="results_uganda/csv_files/coverage.uganda.csv",
    run:
        import pandas as pd
        tmp = []
        for fname in input.fnames_coverage:
            df = pd.read_csv(fname, sep = '\t')
            df['file'] = fname
            tmp.append(df)
        pd.concat(tmp).to_csv(output.fname_coverage)

import os

def get_abs_bam(wildcards):
    return os.path.abspath(f"{wildcards.dataset}/alignments/REF_aln.bam")

rule viloca:
    input:
        fname_bam=get_abs_bam,
        fname_reference=lambda wildcards: os.path.abspath(config['vpipe_uganda']['input']['reference']),
    output:
        fname_csv="{dataset}/variants/cooccurring_mutations.csv",
        fname_vcf="{dataset}/variants/SNVs_0.010000_final.csv",
        dname_haplo=directory("{dataset}/variants/haplotypes"),
        dname_work=directory("{dataset}/variants/"),
    conda:
        "envs/viloca.yaml"
    params:
        window_size=102,
    resources:
        mem_mb=16*8000,
        runtime=14400,
    threads: 16
    shell:
        """
         # Ensure the working directory exists
        mkdir -p {output.dname_work} && \

        # Change to the working directory
        cd {output.dname_work} && \

        viloca run \
            -b {input.fname_bam} \
            -f {input.fname_reference} \
            --mode use_quality_scores \
            --alpha 0.0001 \
            --n_max_haplotypes 100 \
            -w {params.window_size} \
            --min_windows_coverage 1 \
            --win_min_ext 0.8 \
            --threads {threads} \
            --seed 2345 \
            --reuse_files
        """

rule mutations_csv:
    input:
        fnames_csv=expand("{dataset}/variants/SNVs_0.010000_final.csv", dataset= vpipe_uganda.datasets),
    output:
        fname_csv="results_uganda/csv_files/mutations.uganda.csv",
    run:
        import pandas as pd
        tmp = []
        for fname in input.fnames_csv:
            df = pd.read_csv(fname)
            df['file'] = fname
            tmp.append(df)
        pd.concat(tmp).to_csv(output.fname_csv)
